{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":37705,"sourceType":"datasetVersion","datasetId":29561},{"sourceId":239348972,"sourceType":"kernelVersion"}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nos.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n\nimport torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import transforms\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport gc\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T05:33:22.148360Z","iopub.execute_input":"2025-05-18T05:33:22.149017Z","iopub.status.idle":"2025-05-18T05:33:26.527130Z","shell.execute_reply.started":"2025-05-18T05:33:22.148990Z","shell.execute_reply":"2025-05-18T05:33:26.526361Z"}},"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"from diffusers import DDPMScheduler\n\nscheduler = DDPMScheduler(\n    num_train_timesteps=1000, \n    beta_start=0.001, \n    beta_end=0.02\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T05:33:31.294350Z","iopub.execute_input":"2025-05-18T05:33:31.294951Z","iopub.status.idle":"2025-05-18T05:33:32.008519Z","shell.execute_reply.started":"2025-05-18T05:33:31.294927Z","shell.execute_reply":"2025-05-18T05:33:32.007997Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"from diffusers import UNet2DModel\n\nmodel = UNet2DModel(\n    in_channels=3,\n    sample_size=64,\n    block_out_channels=(64, 128, 256, 512),\n    down_block_types=(\"DownBlock2D\", \"DownBlock2D\", \"AttnDownBlock2D\", \"AttnDownBlock2D\"),\n    up_block_types=(\"AttnUpBlock2D\", \"AttnUpBlock2D\", \"UpBlock2D\", \"UpBlock2D\"),\n).to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T05:33:35.171404Z","iopub.execute_input":"2025-05-18T05:33:35.172024Z","iopub.status.idle":"2025-05-18T05:33:53.202576Z","shell.execute_reply.started":"2025-05-18T05:33:35.171998Z","shell.execute_reply":"2025-05-18T05:33:53.201771Z"}},"outputs":[{"name":"stderr","text":"2025-05-18 05:33:39.177548: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1747546419.400043      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1747546419.461496      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"class CelebADataset(Dataset):\n    def __init__(self, root_dir, image_size=64):\n        self.root_dir = root_dir\n        self.image_files = sorted(os.listdir(root_dir))\n        self.transform = transforms.Compose([\n            transforms.CenterCrop(140),\n            transforms.Resize(image_size),\n            transforms.ToTensor(),\n            transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n        ])\n\n    def __len__(self):\n        return len(self.image_files)\n\n    def __getitem__(self, idx):\n        img_path = os.path.join(self.root_dir, self.image_files[idx])\n        image = Image.open(img_path).convert(\"RGB\")\n        return self.transform(image)\n\nimage_folder = \"/kaggle/input/celeba-dataset/img_align_celeba/img_align_celeba\"\ndataset = CelebADataset(image_folder, image_size=64)\ndataloader = DataLoader(dataset, batch_size=64, shuffle=True, num_workers=2)\n\nimages = next(iter(dataloader))\nprint(\"Sample batch shape:\", images.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T05:33:58.481553Z","iopub.execute_input":"2025-05-18T05:33:58.482405Z","iopub.status.idle":"2025-05-18T05:34:01.831413Z","shell.execute_reply.started":"2025-05-18T05:33:58.482377Z","shell.execute_reply":"2025-05-18T05:34:01.830654Z"}},"outputs":[{"name":"stdout","text":"Sample batch shape: torch.Size([64, 3, 64, 64])\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"lr = 1e-4\noptimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n\nstart_epoch = 0\ncheckpoint_path = \"/kaggle/input/notebook21d8941c07/checkpoints/last_checkpoint.pth\"\n\nif os.path.exists(checkpoint_path):\n    checkpoint = torch.load(checkpoint_path, map_location=device)\n    model.load_state_dict(checkpoint['model_state_dict'])\n    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n    start_epoch = checkpoint['epoch'] + 1\n    print(f\"Resuming training from epoch {start_epoch}\")\nelse:\n    print(\"Starting training from scratch.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T05:34:09.405633Z","iopub.execute_input":"2025-05-18T05:34:09.405950Z","iopub.status.idle":"2025-05-18T05:34:15.671910Z","shell.execute_reply.started":"2025-05-18T05:34:09.405923Z","shell.execute_reply":"2025-05-18T05:34:15.671186Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/1426524304.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(checkpoint_path, map_location=device)\n","output_type":"stream"},{"name":"stdout","text":"Resuming training from epoch 10\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import threading\nimport time\n\ndef keep_alive():\n    while True:\n        print(\".\", flush=True)\n        time.sleep(600)\n\nt = threading.Thread(target=keep_alive, daemon=True)\nt.start()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T05:34:21.508574Z","iopub.execute_input":"2025-05-18T05:34:21.509066Z","iopub.status.idle":"2025-05-18T05:34:21.514674Z","shell.execute_reply.started":"2025-05-18T05:34:21.509043Z","shell.execute_reply":"2025-05-18T05:34:21.513948Z"}},"outputs":[{"name":"stdout","text":".\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"losses = []\nos.makedirs(\"checkpoints\", exist_ok=True)\ntotal_epochs = 20\n\nfor epoch in range(start_epoch, total_epochs):\n    model.train()\n\n    for batch in dataloader:\n        clean_images = batch.to(device)\n        noise = torch.randn_like(clean_images).to(device)\n        timesteps = torch.randint(\n            0, scheduler.config.num_train_timesteps, \n            (clean_images.shape[0],), device=device\n        ).long()\n\n        noisy_images = scheduler.add_noise(clean_images, noise, timesteps)\n        noise_pred = model(noisy_images, timesteps, return_dict=False)[0]\n\n        loss = F.mse_loss(noise_pred, noise)\n        losses.append(loss.item())\n\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n        gc.collect()\n        torch.cuda.empty_cache()\n\n    # Save checkpoints\n    torch.save({\n        'epoch': epoch,\n        'model_state_dict': model.state_dict(),\n        'optimizer_state_dict': optimizer.state_dict(),\n        'loss': loss,\n    }, f\"checkpoints/epoch_{epoch:02d}.pth\")\n\n    torch.save({\n        'epoch': epoch,\n        'model_state_dict': model.state_dict(),\n        'optimizer_state_dict': optimizer.state_dict(),\n        'loss': loss,\n    }, \"checkpoints/last_checkpoint.pth\")\n\n    avg_loss = sum(losses[-len(dataloader):]) / len(dataloader)\n    print(f\"Finished epoch {epoch}. Average loss: {avg_loss:.6f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T05:34:26.155706Z","iopub.execute_input":"2025-05-18T05:34:26.156418Z"}},"outputs":[{"name":"stdout","text":".\n.\n.\n.\n.\n.\nFinished epoch 10. Average loss: 0.011151\n.\n.\n.\n.\n.\n.\n.\nFinished epoch 11. Average loss: 0.011031\n.\n.\n.\n.\n.\n.\nFinished epoch 12. Average loss: 0.011044\n.\n.\n.\n.\n.\n.\n.\nFinished epoch 13. Average loss: 0.011006\n.\n.\n.\n.\n.\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"with open('losses.txt', 'w') as file:\n    for loss in losses:\n        file.write(f\"{loss}\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T04:02:22.510467Z","iopub.execute_input":"2025-05-18T04:02:22.511008Z","iopub.status.idle":"2025-05-18T04:02:22.575898Z","shell.execute_reply.started":"2025-05-18T04:02:22.510985Z","shell.execute_reply":"2025-05-18T04:02:22.574923Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_31/154226726.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'losses.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{loss}\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'losses' is not defined"],"ename":"NameError","evalue":"name 'losses' is not defined","output_type":"error"}],"execution_count":1},{"cell_type":"code","source":"from diffusers import DDPMPipeline\nfrom torchvision.utils import save_image, make_grid\nimport numpy as np\n\nmodel.eval()\npipeline = DDPMPipeline(unet=model, scheduler=scheduler)\n\nwith torch.no_grad():\n    ims = pipeline(batch_size=64).images\n\nfig, axes = plt.subplots(8, 8, figsize=(12, 12))\nfor i, img in enumerate(ims):\n    row, col = divmod(i, 8)\n    axes[row, col].imshow(img)\n    axes[row, col].axis('off')\nplt.tight_layout()\nplt.show()\n\ngrid_tensor = torch.tensor(np.stack([transforms.ToTensor()(img) for img in ims]))\ngrid = make_grid(grid_tensor, nrow=8, normalize=True)\nsave_image(grid, \"generated_images.png\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T20:57:23.891003Z","iopub.execute_input":"2025-05-12T20:57:23.891250Z","iopub.status.idle":"2025-05-12T21:00:42.049566Z","shell.execute_reply.started":"2025-05-12T20:57:23.891234Z","shell.execute_reply":"2025-05-12T21:00:42.049009Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.subplots(1, 2, figsize=(12, 4))\n\nplt.subplot(1, 2, 1)\nplt.plot(losses)\nplt.title(\"Training loss\")\nplt.xlabel(\"Training step\")\n\nplt.subplot(1, 2, 2)\nplt.plot(range(400, len(losses)), losses[400:])\nplt.title(\"Training loss from step 400\")\nplt.xlabel(\"Training step\");","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T21:25:08.479276Z","iopub.execute_input":"2025-05-12T21:25:08.479894Z","iopub.status.idle":"2025-05-12T21:25:09.026781Z","shell.execute_reply.started":"2025-05-12T21:25:08.479869Z","shell.execute_reply":"2025-05-12T21:25:09.026030Z"}},"outputs":[],"execution_count":null}]}